# AirFlow_Kafka_Spark_Docker
This is a recipe for Composing ingredients based on airflow, kafka,spark and cooking it in docker containers using docker-compose.

This is Like Story Telling , 

To Stream data , consuming it to tables and writing queries to get some insights. However, it often comes with additional overhead. Luckily, there are tools that allow you to automate many parts of this process.Â 

This repository takes on the topic of Streaming Data , Capturing it and getting insights. It mainly leans on three nifty tools, being [Kafka](https://github.com/apache/kafka), [Airflow](https://github.com/apache/airflow), and [Spark](https://github.com/apache/spark). 

# PLease Read the Story telling first to understand step by step recipe making (Medium Post ):-

The corresponding [walkthrough/post](https://medium.com/@rose4earn/docker-compose-ing-kafka-airflow-spark-b2ea66993c50) on Medium lays out the workings of this repo step-by-step.

